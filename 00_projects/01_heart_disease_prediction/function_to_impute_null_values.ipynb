{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1799d036",
   "metadata": {},
   "source": [
    "# Missing Values Imputation Function Using ML\n",
    "### `Author:` [`Khizer Rehman`](khizerr776@gmail.com)\n",
    "### `Date:` 01-05-2025\n",
    "\n",
    "#### **Steps:**\n",
    "1. Import all the necessary Libraries\n",
    "2. Load the data\n",
    "3. Find the columns with the missing values and store in a object\n",
    "4. Find the columns based on data type\n",
    "   1. Numeric\n",
    "   2. Categoricals\n",
    "   3. Boolean \n",
    "5. Define the function to impute missing values\n",
    "6. Apply the function to our dataset with missing values \n",
    "7. Check the missing values after imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f98c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, r2_score, mean_squared_error\n",
    "\n",
    "# importing the iterative imputer \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# import the train_test_split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119fcec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trestbps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fbs",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "restecg",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "thalch",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exang",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "slope",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ca",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "thal",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "79d0b5bc-0f1b-4aaf-b0b8-6bfb8c4c9ecf",
       "rows": [
        [
         "0",
         "1",
         "63",
         "Male",
         "Cleveland",
         "typical angina",
         "145.0",
         "233.0",
         "True",
         "lv hypertrophy",
         "150.0",
         "False",
         "2.3",
         "downsloping",
         "0.0",
         "fixed defect",
         "0"
        ],
        [
         "1",
         "2",
         "67",
         "Male",
         "Cleveland",
         "asymptomatic",
         "160.0",
         "286.0",
         "False",
         "lv hypertrophy",
         "108.0",
         "True",
         "1.5",
         "flat",
         "3.0",
         "normal",
         "2"
        ],
        [
         "2",
         "3",
         "67",
         "Male",
         "Cleveland",
         "asymptomatic",
         "120.0",
         "229.0",
         "False",
         "lv hypertrophy",
         "129.0",
         "True",
         "2.6",
         "flat",
         "2.0",
         "reversable defect",
         "1"
        ],
        [
         "3",
         "4",
         "37",
         "Male",
         "Cleveland",
         "non-anginal",
         "130.0",
         "250.0",
         "False",
         "normal",
         "187.0",
         "False",
         "3.5",
         "downsloping",
         "0.0",
         "normal",
         "0"
        ],
        [
         "4",
         "5",
         "41",
         "Female",
         "Cleveland",
         "atypical angina",
         "130.0",
         "204.0",
         "False",
         "lv hypertrophy",
         "172.0",
         "False",
         "1.4",
         "upsloping",
         "0.0",
         "normal",
         "0"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(\"./heart_disease_uci.csv\")   # . indecated the file is in the same directory as the script\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a4802c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalch',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want the only columns with missing values\n",
    "missing_data_cols= df.isnull().sum()[df.isnull().sum() > 0 ].index.tolist()\n",
    "missing_data_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa1ae2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:  ['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
      "Numerical columns:  ['id', 'age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca', 'num']\n"
     ]
    }
   ],
   "source": [
    "# find only the categorical columns from the dataset\n",
    "cat_cols = df.select_dtypes(include= 'object').columns.tolist()\n",
    "\n",
    "# find the numerical columns from the dataset\n",
    "num_cols = df.select_dtypes(exclude = 'object').columns.tolist()\n",
    "\n",
    "print(\"Categorical columns: \", cat_cols)\n",
    "print(\"Numerical columns: \", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c8908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bb5ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the categorical columns that we want to encode\n",
    "categorical_cols = ['thal', 'ca', 'slope', 'exang', 'restecg', 'fbs', 'cp', 'sex', 'num']\n",
    "\n",
    "# create the list for boolean columns\n",
    "bool_cols = ['fbs', 'exang']\n",
    "\n",
    "# create the list same for numerical columns\n",
    "numerical_cols = ['oldpeak', 'thalch', 'chol', 'trestbps', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5639a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we may use this function to store all the label encoders in one place\n",
    "\n",
    "class store_encoders:\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        # create a dictionary to store all the encoders\n",
    "        self.encoders = {}\n",
    "\n",
    "    # add the label encoder to the dictionary\n",
    "    def add_encoder(self, name, encoder):\n",
    "        if name in self.encoders:\n",
    "            raise ValueError(f\"Label Encoder for '{name}' already exists.\") \n",
    "        self.encoders[name] = encoder\n",
    "    \n",
    "    # get the encoder by its name    \n",
    "    def get_encoder(self, name):\n",
    "        if name not in self.encoders:\n",
    "            raise ValueError(f\"Label Encoder for '{name}' does not exist.\")\n",
    "        return self.encoders[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafef7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to store all the encoders in one place \n",
    "'''\n",
    "label_encoders = {}\n",
    "le = encoder_store()\n",
    "label_encoders[col] = le\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb001e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to impute missing values in the dataset\n",
    "\n",
    "def impute_categorical_missing_data(pass_col):\n",
    "    '''\n",
    "    * first of all we will create a dataFrame with all the missing values\n",
    "    of pass_col and other columns remain same as in original dataframe\n",
    "    * secondly we will create another dataFrame without the missing values\n",
    "    of pass_col and other will remain same as in original dataframe\n",
    "    '''\n",
    "\n",
    "    df_null = df[df[pass_col].isnull()]                      \n",
    "    df_not_null = df[df[pass_col].notnull()]     \n",
    "\n",
    "    '''\n",
    "    Spliting the dataframe into freature and target so,\n",
    "    df_not_null and drop the pass_col in X.\n",
    "    y having only pass_col column of that dataframe\n",
    "    '''\n",
    "    # spliting the df_without_missing_values into features and target variables in X and y\n",
    "    X = df_not_null.drop(pass_col, axis=1)    # drop the pass_col from the original dataframe so features are all the columns other than pass_col \n",
    "    y = df_not_null[pass_col]                 # target variable is the pass_col in the original dataframe which we have to predict for the missing values\n",
    "\n",
    "    '''\n",
    "    Extract other columns with missing valuse from X\n",
    "    to impute their missing values to train the model\n",
    "    '''\n",
    "    other_missing_cols = [col for col in missing_data_cols if col != pass_col]\n",
    "\n",
    "    '''\n",
    "    use the labelEncoder on all the categorical and object dtype columns\n",
    "    of X\n",
    "    '''\n",
    "    \n",
    "    # Encode the categorical columns by using labelEncoder\n",
    "    # label_Encoders = {}                      # dictionary to store all the label encoders \n",
    "\n",
    "    # initialize the store_encoder class\n",
    "    Label_encoders = store_encoders()\n",
    "\n",
    "    for col in X.columns:\n",
    "\n",
    "        # check if the column is categorical or object\n",
    "        if X[col].dtype == 'category' or X[col].dtype == 'object':\n",
    "            \n",
    "            # initialize the LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "\n",
    "\n",
    "            # using add function of the store_encoders class\n",
    "            Label_encoders.add_encoder(col, le)\n",
    "            \n",
    "            # label_Encoders[col] = le          # store the all the encoder in the dictionary\n",
    "    \n",
    "    # check if the pass_col is a boolean then also encode it\n",
    "    if pass_col in bool_cols:\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    \n",
    "    # initialize the IterativeImputer to impute the missing values \n",
    "    iterative_imputer = IterativeImputer(estimator = RandomForestRegressor(random_state = 42), add_indicator = True)\n",
    "    \n",
    "    # impute the missing values of other missing columns of X\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "\n",
    "            # change the shape of 1D array to 2D because iterativeImputer expects 2D array\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            \n",
    "            # fit_transform the IterativeImputer on that column to remove missing values\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "\n",
    "            # slice the first column of the imputed_values 2D array and convert into 1D\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # spliting the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state= 42)           \n",
    "\n",
    "    # initialize the random forest classifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    # fit the model on the training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target variable for the test data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # print the accuracy and precision of the model\n",
    "    print(\"The Feature '\" +pass_col+ \"' has been imputed with \", round(accuracy * 100),2), \"accuracy\\n\"\n",
    "    \n",
    "    # dataset with all the null values of pass_col and we will remove pass_col from X \n",
    "    X = df_null.drop(pass_col, axis=1)\n",
    "\n",
    "    # use the label encoders to encode the categorical and object dtype columns of X\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'category' or X[col].dtype == 'object':\n",
    "            X[col] = Label_encoders.get_encoder(col).transform(X[col])\n",
    "    \n",
    "    # impute the missing values of other missing columns of X\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "\n",
    "            # change the shape of 1D array to 2D because iterativeImputer expects 2D array\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            \n",
    "            # fit_transform the IterativeImputer on that column to remove missing values\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "\n",
    "            # slice the first column of the imputed_values 2D array and convert into 1D\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # predict the target variable for the null values of \n",
    "    if len(df_null)>0:\n",
    "        df_null[pass_col] = rf_classifier.predict(X)\n",
    "        if pass_col in bool_cols:\n",
    "            df_null[pass_col] = df_null[pass_col].map({0: False, 1: True})\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null])\n",
    "    \n",
    "    return df_combined[pass_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9411035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to impute the continuous missing values\n",
    "def impute_continuous_missing_data(pass_col):\n",
    "    \n",
    "    df_null = df[df[pass_col].isnull()]\n",
    "    df_not_null = df[df[pass_col].notnull()]\n",
    "\n",
    "    X = df_not_null.drop(pass_col, axis=1)\n",
    "    y = df_not_null[pass_col]\n",
    "    \n",
    "    other_missing_cols = [col for col in missing_data_cols if col != pass_col]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "    \n",
    "    iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf_regressor = RandomForestRegressor()\n",
    "\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    print(\"MAE =\", mean_absolute_error(y_test, y_pred), \"\\n\")\n",
    "    print(\"RMSE =\", np.sqrt(mean_squared_error(y_test, y_pred)), \"\\n\")\n",
    "    print(\"R2 =\", r2_score(y_test, y_pred), \"\\n\")\n",
    "\n",
    "    X = df_null.drop(pass_col, axis=1)\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    if len(df_null) > 0: \n",
    "        df_null[pass_col] = rf_regressor.predict(X)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null])\n",
    "    \n",
    "    return df_combined[pass_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57f1a812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca          611\n",
       "thal        486\n",
       "slope       309\n",
       "fbs          90\n",
       "oldpeak      62\n",
       "trestbps     59\n",
       "thalch       55\n",
       "exang        55\n",
       "chol         30\n",
       "restecg       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99c083da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values trestbps : 6.41%\n",
      "MAE = 13.062774566473987 \n",
      "\n",
      "RMSE = 17.05816885997707 \n",
      "\n",
      "R2 = 0.0914630061972822 \n",
      "\n",
      "Missing Values chol : 3.26%\n",
      "MAE = 45.03202247191012 \n",
      "\n",
      "RMSE = 64.06515594878056 \n",
      "\n",
      "R2 = 0.6748659747124507 \n",
      "\n",
      "Missing Values fbs : 9.78%\n",
      "The Feature 'fbs' has been imputed with  81 2\n",
      "Missing Values restecg : 0.22%\n",
      "The Feature 'restecg' has been imputed with  65 2\n",
      "Missing Values thalch : 5.98%\n",
      "MAE = 16.695664739884393 \n",
      "\n",
      "RMSE = 21.633393275773393 \n",
      "\n",
      "R2 = 0.3194835865910084 \n",
      "\n",
      "Missing Values exang : 5.98%\n",
      "The Feature 'exang' has been imputed with  80 2\n",
      "Missing Values oldpeak : 6.74%\n",
      "MAE = 0.5633837209302327 \n",
      "\n",
      "RMSE = 0.7911434982882188 \n",
      "\n",
      "R2 = 0.4036949703841892 \n",
      "\n",
      "Missing Values slope : 33.59%\n",
      "The Feature 'slope' has been imputed with  66 2\n",
      "Missing Values ca : 66.41%\n",
      "The Feature 'ca' has been imputed with  63 2\n",
      "Missing Values thal : 52.83%\n",
      "The Feature 'thal' has been imputed with  72 2\n"
     ]
    }
   ],
   "source": [
    "# remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# impute missing values using our functions\n",
    "for col in missing_data_cols:\n",
    "    print(\"Missing Values\", col, \":\", str(round((df[col].isnull().sum() / len(df)) * 100, 2))+\"%\")\n",
    "    if col in categorical_cols:\n",
    "        df[col] = impute_categorical_missing_data(col)\n",
    "    elif col in numerical_cols:\n",
    "        df[col] = impute_continuous_missing_data(col)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6264a5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "age         0\n",
       "sex         0\n",
       "dataset     0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalch      0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
