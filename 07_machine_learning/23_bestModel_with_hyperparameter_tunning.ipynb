{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Best Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the preprocessing modules \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# import all the models which we have to use in this noteBook \n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# import the cross validation module \n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "\n",
    "# import the metrics to evalute the models \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"tips\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can select the feature and targets or labels from the dataset\n",
    "# features\n",
    "X = df.drop('tip', axis=1)\n",
    "\n",
    "# Targets \n",
    "y = df['tip']\n",
    "\n",
    "# now, we encode all the categorical variables by using labelencoder\n",
    "for col in X.columns:\n",
    "    le = LabelEncoder()\n",
    "    if X[col].dtype =='category' or X[col].dtype == 'object':\n",
    "        X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the list of models which we want to use \n",
    "models = [\n",
    "    (\"SVM\", SVR()),\n",
    "    (\"XGBoost\", XGBRegressor()),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor()),\n",
    "    (\"Liner Regression\", LinearRegression()),\n",
    "    (\"KNeighbors\", KNeighborsRegressor()),\n",
    "    (\"Random Forest\", RandomForestRegressor()),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor())\n",
    "]\n",
    "model_score = []\n",
    "# fitting , predicting and evaluating the each model by using for loop \n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluating the model\n",
    "    mar = mean_absolute_error(y_test, y_pred)\n",
    "    model_score.append((name, mar))\n",
    "\n",
    "short_models = sorted(model_score, key=lambda x: x[1], reverse=False)\n",
    "for model in short_models:\n",
    "    print(f\"Mean Absolute Error for {model[0]} is {model[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "higher (high and low)\n",
    "lower (high and low)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# creating the list of models which we want to compare\n",
    "models = {\n",
    "    \"SVM\": SVR(),\n",
    "    \"XGBoost\": XGBRegressor(), \n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"KNeighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "}\n",
    "\n",
    "model_score = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # fitting the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predicting the model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluating the model by using Root Mean Squared Error (RMSE)\n",
    "    rmse = root_mean_squared_error(y_test , y_pred)\n",
    "    model_score.append((name, rmse))\n",
    "\n",
    "short_models = sorted(model_score, key=lambda x: x[1], reverse=False)\n",
    "for model in short_models:\n",
    "    print(f\"Root Mean Squared Error for {model[0]} is {model[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"SVM\": (\n",
    "        SVR(),      \n",
    "        {\n",
    "            'kernel': ['linear', 'poly', 'rbf'],\n",
    "            'C': [1.0, 0.1, 0.01],\n",
    "            'epsilon': [0.1, 0.01, 0.001],\n",
    "            'gamma': ['auto'],\n",
    "            'shrinking': [True, False],\n",
    "            'cache_size': [50, 100, 200],\n",
    "            'verbose': [True, False]\n",
    "        }\n",
    "    ),\n",
    "    \"Random Forest\": (\n",
    "        RandomForestRegressor(),\n",
    "        {\n",
    "            'n_estimators': [10, 100, 1000],\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    ),\n",
    "    \"KNN\": (\n",
    "        KNeighborsRegressor(),\n",
    "        {\n",
    "            'n_neighbors': [5, 10, 15],\n",
    "            'algorithm': ['kd_tree', 'ball_tree'],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "        }\n",
    "    ),\n",
    "    \"Decision Tree\": (\n",
    "        DecisionTreeRegressor(), \n",
    "        {\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        }\n",
    "    ),\n",
    "    \"Linear Regression\": (\n",
    "        LinearRegression(), {}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBRegressor(),\n",
    "        {\n",
    "            'n_estimators': [10, 100]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "model_score = []\n",
    "\n",
    "# loop through each model\n",
    "\n",
    "for name, (model, param) in models.items():\n",
    "    # create a pipeline\n",
    "    pipeline = GridSearchCV(model, param, cv=5)\n",
    "\n",
    "    # fit the pipeline to the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    model_score.append((name, mse))\n",
    "\n",
    "short_models = sorted(model_score, key=lambda x: x[1], reverse=False)\n",
    "for model in short_models:\n",
    "    print(f\"Mean Squared Error for {model[0]} is {model[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def karperkar_routine(num):\n",
    "    step = 0\n",
    "    print(f'This is your Number: {num}')\n",
    "\n",
    "    while num != 6174:\n",
    "        num_str = f\"{num:04d}\"\n",
    "        largest = (\"\".join(sorted(num_str, reverse=True)))\n",
    "        smallest = (\"\".join(sorted(num_str)))\n",
    "        num = largest - smallest\n",
    "        print(f'Step {step}: {largest} - {smallest} = {num}')\n",
    "    print(\"Reached 6174 in {step} stepsðŸŽ‰\") \n",
    "# Get user Input       \n",
    "user_input = input(\"Please Enter a 4 digit number:\")\n",
    "if user_input.isdigit() & len(user_input) == 4 &  len(set(int(user_input))) > 1:\n",
    "    karperkar_routine(int(user_input))\n",
    "else:\n",
    "    print(\"Envalid User Input.4 digit number with at least 1 different number\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
